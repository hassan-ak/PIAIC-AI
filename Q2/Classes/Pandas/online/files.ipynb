{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data Loading, Storage, and File Formats\n",
    "\n",
    "\n",
    "* Topic Reading and Writing Data in Text Format  \n",
    "Parsing functions in pandas  \n",
    "\n",
    "* read_csv = load delimited data from a file, URL, or file-like   \n",
    "object; use comma as default delimiter\n",
    "* read_excel = Read tabular data from an Excel XLS or XLSX file\n",
    "* read_html = Read all tables found in the given HTML document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# common options in these functions  \n",
    "\n",
    "\n",
    "* Indexing  \n",
    "Can treat one or more columns as the returned DataFrame, and whether to get\n",
    "column names from the file, the user, or not at all.  \n",
    "  \n",
    "  \n",
    "* Type inference and data conversion  \n",
    "This includes the user-defined value conversions and custom list of missing value\n",
    "markers.\n",
    "  \n",
    "  \n",
    "* Datetime parsing  \n",
    "Includes combining capability, including combining date and time information\n",
    "spread over multiple columns into a single column in the result.  \n",
    "\n",
    "\n",
    "* Iterating  \n",
    "Support for iterating over chunks of very large files.  \n",
    "  \n",
    "  \n",
    "* Unclean data issues  \n",
    "Skipping rows or a footer, comments, or other minor things like numeric data with thousands separated by commas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "download examples folder from our provide link or book resources\n",
    "\n",
    "# loading it into pandas data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_df= pd.read_csv(\"examples/sample.csv\")\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What if no column names available\n",
    "#(we are removing first row)\n",
    "\n",
    "sample_df= pd.read_csv(\"examples/sample.csv\")\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can change the column names while loading data\n",
    "sample_df=pd.read_csv(\"examples/sample.csv\",skiprows=1,\n",
    "                     names=['id', 'name', 'ch', 'ph', 'en', 'math'])\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer the book for other details like header=None  etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df= pd.read_csv(\"examples/ex1.csv\")\n",
    "print(sample_df)\n",
    "print()\n",
    "sample_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchal Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_df = pd.read_csv(\"examples/sample2.csv\")\n",
    "print(s2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to specifiy which column will be used as index\n",
    "parsed = pd.read_csv('examples/sample2.csv', index_col='key1')\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('examples/sample2.csv',index_col=['key1', 'key2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use of other delimiter are also possible\n",
    "#In some cases, a table might not have a fixed delimiter, using whitespace or some\n",
    "#other pattern to separate fields\n",
    "#checkout [21] and [24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('examples/sample3.csv')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('examples/sample3.csv', na_values=['NULL'])#\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing data while loading in dataframe\n",
    "#diconary=  column name : [source values, target value]#\n",
    "sentinels = {'message': ['foo', 'NA']}\n",
    "pd.read_csv('examples/sample3.csv', na_values=sentinels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing values is an important and frequently nuanced part of the file parsing process. Missing data is usually either not present (empty string) or marked by\n",
    "some sentinel value. By default, pandas uses a set of commonly occurring sentinels,\n",
    "such as NA and NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and  Text Files in Pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting selected rows from a large datasets\n",
    "pd.read_csv('examples/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('examples/train.csv', nrows=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To read a file in pieces, specify a chunksize as a number of rows:\n",
    "chunks = pd.read_csv('examples/train.csv', chunksize=200)\n",
    "print(type(chunks), print(chunks) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkList = []\n",
    "for chunk in chunks:\n",
    "    chunkList.append(chunk)\n",
    "\n",
    "df = chunkList[1] \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(open('examples/ex3.txt'))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use spaces (one or more ) as delimiter \n",
    "result = pd.read_table('examples/ex3.txt', sep='\\s+')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('examples/ex4.csv', skiprows=[0, 2, 3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table 6-2. Some read_csv/read_table function arguments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Data to Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('examples/ex5.csv')\n",
    "print(data)\n",
    "data.to_csv('examples/out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dates = pd.date_range('1/1/2000', periods=7)\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.Series(np.arange(7), index=dates)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.to_csv(\"examples/tseries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Data\n",
    "short for JavaScript Object Notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    "\"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n",
    "\"pet\": null,\n",
    "\"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n",
    "{\"name\": \"Katie\", \"age\": 38,\n",
    "\"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]\n",
    "}\n",
    "\"\"\"\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same like dictionary\n",
    "data = pd.read_json('examples/example.json')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML and HTML: Web   data loading in to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install lxml\n",
    "# conda install -c anaconda beautifulsoup4 \n",
    "# htconda install -c anaconda html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tables = pd.read_html('examples/fdic_failed_bank_list.html')\n",
    "# tables variable type is not dataframe, its list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_df = tables[0]\n",
    "print(type(failures_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(failures_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: data is bit lengthy in this data frame\n",
    "print(failures_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(failures_df[\"City\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(failures_df[\"Bank Name\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(failures_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for large and complicated dataframe, try to extract\n",
    "# data as series for review and analysis\n",
    "# here we converted a column into a new series of date type\n",
    "close_timestamps = pd.to_datetime(failures_df['Closing Date'])\n",
    "print(type(close_timestamps),close_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Data Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('examples/ex1.csv')\n",
    "frame.to_pickle('examples/frame_pickle')\n",
    "pd.read_pickle('examples/frame_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using HDF5 Format\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "frame = pd.DataFrame({'a': np.random.randn(100)})\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore('examples/mydata.h5')\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store['obj1'] = frame\n",
    "store['obj1_col'] = frame['a']\n",
    "print(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=store.obj1\n",
    "print(type(x))\n",
    "print(x.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.put('obj2', frame, format='table')\n",
    "store.select('obj2', where=['index >= 10 and index <= 15'])\n",
    "store.close()\n",
    "frame.to_hdf('mydata.h5', 'obj3', format='table')\n",
    "frame = pd.read_hdf('mydata.h5', 'obj3', where=['index < 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Microsoft Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading\n",
    "import pandas as pd\n",
    "\n",
    "xlsx = pd.ExcelFile('examples/ex1.xlsx')\n",
    "pd.read_excel(xlsx, 'Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_excel('examples/ex1.xlsx', 'Sheet1')\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing\n",
    "writer = pd.ExcelWriter('examples/ex2.xlsx')\n",
    "frame.to_excel(writer, 'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative option for single sheet\n",
    "frame.to_excel('examples/ex3.xlsx')\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interacting with Web APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "url = 'https://api.github.com/repos/pandas-dev/pandas/issues'\n",
    "resp = requests.get(url)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = resp.json()\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data[0]\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dict['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = pd.DataFrame(data, \n",
    "                    columns=['number', 'title','labels', 'state'])\n",
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = pd.DataFrame(data)\n",
    "issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(issues[['number', 'title']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interacting with Databases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c anaconda sqlite \n",
    "\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "#creating table\n",
    "query = \"\"\" CREATE TABLE test(a VARCHAR(20), \n",
    "        b VARCHAR(20),c REAL,\n",
    "        d INTEGER);  \"\"\"\n",
    "# creating database file\n",
    "con = sqlite3.connect('examples/mydata.sqlite')\n",
    "#running query\n",
    "con.execute(query)\n",
    "# table created\n",
    "con.commit()\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserting data\n",
    "#preparing data\n",
    "data = [('Atlanta', 'Georgia', 1.25, 6),\n",
    "        ('Tallahassee', 'Florida', 2.6, 3),\n",
    "        ('Sacramento', 'California', 1.7, 5)\n",
    "       ]\n",
    "# preparing insert statement\n",
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\n",
    "# running insert statement\n",
    "con.executemany(stmt, data)\n",
    "#finalizing data saving\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting/extracting data\n",
    "cursor = con.execute('select * from test')\n",
    "rows = cursor.fetchall()\n",
    "print(type(rows), rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cursor.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(rows, columns=[x[0] for x in cursor.description])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c anaconda sqlalchemy \n",
    "# using sqlalchemy \n",
    "import sqlalchemy as sqla\n",
    "db = sqla.create_engine('sqlite:///mydata.sqlite')\n",
    "data_df =pd.read_sql('select * from test', db)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end of six chapter\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
